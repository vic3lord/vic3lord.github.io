<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Build a datalake on top of BigQuery | Or Elimelech</title><meta name=keywords content="bigquery,data,google-cloud"><meta name=description content="Google BigQuery is a very powerful, serverless data warehosue that
lets you ingest unlimited data on a pay-per-use basis (storage + querying).
The primary advantage of data warehouses is the ability to quickly query and analyze immense amounts of structured data.
Modern data warehouses support new, unstructured data types such as JSON, Avro, and so on, which makes these data warehouses a great contender for data lakes.
BigQuery recently added native JSON column type, which we can leverage for our semi-structured lakehouse.
With JSON support we can skip the traditional datalakes that are just blob storage with files, from classic Hadoop + hive through GCS, S3, Athena etc.
Maintaining such infrastructure and understanding the low-level components, such as metastore, ORC, and Parquet is an expensive process for most startups, financially and with regard to domain expertise."><meta name=author content="Or Elimelech"><link rel=canonical href=https://or-e.net/posts/bigquery-lakehouse/><link crossorigin=anonymous href=/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css integrity="sha256-j+ECM6cGvIfy4Is8+XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as=style><link rel=icon href=https://or-e.net/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://or-e.net/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://or-e.net/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://or-e.net/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://or-e.net/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://or-e.net/posts/bigquery-lakehouse/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://or-e.net/posts/bigquery-lakehouse/"><meta property="og:site_name" content="Or Elimelech"><meta property="og:title" content="Build a datalake on top of BigQuery"><meta property="og:description" content="Google BigQuery is a very powerful, serverless data warehosue that lets you ingest unlimited data on a pay-per-use basis (storage + querying). The primary advantage of data warehouses is the ability to quickly query and analyze immense amounts of structured data.
Modern data warehouses support new, unstructured data types such as JSON, Avro, and so on, which makes these data warehouses a great contender for data lakes. BigQuery recently added native JSON column type, which we can leverage for our semi-structured lakehouse. With JSON support we can skip the traditional datalakes that are just blob storage with files, from classic Hadoop + hive through GCS, S3, Athena etc. Maintaining such infrastructure and understanding the low-level components, such as metastore, ORC, and Parquet is an expensive process for most startups, financially and with regard to domain expertise."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-03-14T00:00:00+00:00"><meta property="article:modified_time" content="2022-03-14T00:00:00+00:00"><meta property="article:tag" content="Bigquery"><meta property="article:tag" content="Data"><meta property="article:tag" content="Google-Cloud"><meta property="og:image" content="https://or-e.net/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://or-e.net/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Build a datalake on top of BigQuery"><meta name=twitter:description content="Google BigQuery is a very powerful, serverless data warehosue that
lets you ingest unlimited data on a pay-per-use basis (storage + querying).
The primary advantage of data warehouses is the ability to quickly query and analyze immense amounts of structured data.
Modern data warehouses support new, unstructured data types such as JSON, Avro, and so on, which makes these data warehouses a great contender for data lakes.
BigQuery recently added native JSON column type, which we can leverage for our semi-structured lakehouse.
With JSON support we can skip the traditional datalakes that are just blob storage with files, from classic Hadoop + hive through GCS, S3, Athena etc.
Maintaining such infrastructure and understanding the low-level components, such as metastore, ORC, and Parquet is an expensive process for most startups, financially and with regard to domain expertise."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://or-e.net/posts/"},{"@type":"ListItem","position":2,"name":"Build a datalake on top of BigQuery","item":"https://or-e.net/posts/bigquery-lakehouse/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Build a datalake on top of BigQuery","name":"Build a datalake on top of BigQuery","description":"Google BigQuery is a very powerful, serverless data warehosue that lets you ingest unlimited data on a pay-per-use basis (storage + querying). The primary advantage of data warehouses is the ability to quickly query and analyze immense amounts of structured data.\nModern data warehouses support new, unstructured data types such as JSON, Avro, and so on, which makes these data warehouses a great contender for data lakes. BigQuery recently added native JSON column type, which we can leverage for our semi-structured lakehouse. With JSON support we can skip the traditional datalakes that are just blob storage with files, from classic Hadoop + hive through GCS, S3, Athena etc. Maintaining such infrastructure and understanding the low-level components, such as metastore, ORC, and Parquet is an expensive process for most startups, financially and with regard to domain expertise.\n","keywords":["bigquery","data","google-cloud"],"articleBody":"Google BigQuery is a very powerful, serverless data warehosue that lets you ingest unlimited data on a pay-per-use basis (storage + querying). The primary advantage of data warehouses is the ability to quickly query and analyze immense amounts of structured data.\nModern data warehouses support new, unstructured data types such as JSON, Avro, and so on, which makes these data warehouses a great contender for data lakes. BigQuery recently added native JSON column type, which we can leverage for our semi-structured lakehouse. With JSON support we can skip the traditional datalakes that are just blob storage with files, from classic Hadoop + hive through GCS, S3, Athena etc. Maintaining such infrastructure and understanding the low-level components, such as metastore, ORC, and Parquet is an expensive process for most startups, financially and with regard to domain expertise.\nData Lakes Let’s take a step back and look at standard data lakes. This will lay the foundation for clearly understanding the benefits of using BigQuery for these modern, advanced workloads that contain unstructred data. Data lakes are built for unstructured data using blob storage systems by using efficient compression and columnar data files, such as Parquet. The files are partitioned using a special directory structure for the given time range, making it easy to scan specific time ranges. Now, ideally we need to make it even faster to query lots of data for a specific event_name. To do this, we need to use another component called metastore.\nMetastore is a meta-data storage system that can index certain properties of the data, which makes it easier to pinpoint the correct files containing the relevant data. We have two separate large-scale systems that data engineers need to manage. Filesystems are cumbersome and much more difficult to both query and maintain.\nIt’s worth noting that blob storage has several clear advantages:\nCheaper to store data. Contains storage tiers, such as archival, cold, and warm. Can hold data of any type or size (audio, images, executables, etc.). Real unstructured data like audio can be used for ML piplines, text-to-speech algorithms, etc. Easy to replicate across regions and providers. What’s a data lakehouse? A data warehouse is storage for structured data. A data lake is storage for unstructured data. A data lakehouse is the beautiful storage love child of the warehouse and lake. The lakehouse leverages the semi-structured JSON column of BigQuery and helps us ingest a flexible data structure while the native columns act as our metastore.\nLakehouse example In this example, we use several columns for partioning (timestamp) and clustering (event_name, source). They act as metadata to our semi-structured data. This way it’s easy to navigate and explore data via SQL and to narrow down the subset of data we need. We can then use the new native JSON notation in our query:\nSELECT id, timestamp, event_name, data.hello FROM datalake Next, we use materialized-views or scheduled queries (via BigQuery/Airflow etc.) to build our final facts and dimensions tables.\nid timestamp event_name source content_type data data_bytes 6EF89A2E-8E11-4848-91B3-11682020559F Sun Mar 6 15:48:24 IST 2022 something_happened service-a application/json {\"hello\": \"from lakehouse\"} NULL Easy ETLs with materialized-views IMHO SQL is a great language to use to describe data. SQL is making a noticeable come back. Even Elastic and MongoDB support SQL. The rise of new-SQL databases like CockroachDB, modern warehouses, logging systems, etc. are clear evidence that SQL is here to stay.\nWe will use a cheap form of ETL using BigQuery’s materialized-view feature. The default refresh rate for materialized-view is 30m, you can of course tweak that, but it’s sufficient for most workloads.\nIf you already have such system in place you can use it as well. See: Airflow, dbt or just a simple Kubernetes job.\nCREATE MATERIALIZED VIEW `\u003cproject_id\u003e.\u003cdataset\u003e.canary_tests` PARTITION BY TIMESTAMP_TRUNC(timestamp, HOUR) CLUSTER BY service_name AS SELECT timestamp, data.service_name AS service_name, data.job_name AS job_name, data.workflow_id AS workflow_id, data.test_name AS test_name, data.build_url as build_url, FROM `\u003cproject_id\u003e.\u003cdataset\u003e.datalake_v1` WHERE event_name = \"something_happened\" Conclusion BigQuery is an excellent candidate to serve as the basis for your next data lake adventure (good luck!).\nBigQuery can help you start small and easily scale out. Organizations of all sizes will benefit (if you don’t store anything you won’t pay for it). Data engineering teams can build an impressive data platform levereging the power of SQL. ","wordCount":"711","inLanguage":"en","image":"https://or-e.net/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2022-03-14T00:00:00Z","dateModified":"2022-03-14T00:00:00Z","author":{"@type":"Person","name":"Or Elimelech"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://or-e.net/posts/bigquery-lakehouse/"},"publisher":{"@type":"Organization","name":"Or Elimelech","logo":{"@type":"ImageObject","url":"https://or-e.net/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://or-e.net/ accesskey=h title="Home (Alt + H)">Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://or-e.net/about/ title=About><span>About</span></a></li><li><a href=https://or-e.net/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://or-e.net/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://or-e.net/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://or-e.net/>Home</a>&nbsp;»&nbsp;<a href=https://or-e.net/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Build a datalake on top of BigQuery</h1><div class=post-meta><span title='2022-03-14 00:00:00 +0000 UTC'>March 14, 2022</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Or Elimelech&nbsp;|&nbsp;<a href=https://github.com/vic3lord/vic3lord.github.io/tree/master/content/posts/bigquery-lakehouse.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><div class=post-content><p>Google BigQuery is a very powerful, serverless data warehosue that
lets you ingest unlimited data on a pay-per-use basis (storage + querying).
The primary advantage of data warehouses is the ability to quickly query and analyze immense amounts of <strong>structured</strong> data.</p><p>Modern data warehouses support new, unstructured data types such as JSON, Avro, and so on, which makes these data warehouses a great contender for data lakes.
BigQuery recently added native JSON column type, which we can leverage for our semi-structured lakehouse.
With JSON support we can skip the traditional datalakes that are just blob storage with files, from classic Hadoop + hive through GCS, S3, Athena etc.
Maintaining such infrastructure and understanding the low-level components, such as metastore, ORC, and Parquet is an expensive process for most startups, financially and with regard to domain expertise.</p><h2 id=data-lakes>Data Lakes<a hidden class=anchor aria-hidden=true href=#data-lakes>#</a></h2><p>Let&rsquo;s take a step back and look at standard data lakes. This will lay the foundation for clearly understanding the benefits of using BigQuery for these modern, advanced workloads that contain unstructred data.
Data lakes are built for unstructured data using blob storage systems by using efficient compression and columnar data files, such as Parquet.
The files are partitioned using a special directory structure for the given time range, making it easy to scan specific time ranges.
Now, ideally we need to make it even faster to query lots of data for a specific <code>event_name</code>. To do this, we need to use another component called metastore.</p><p>Metastore is a meta-data storage system that can index certain properties of the data, which makes it easier to pinpoint the correct files containing the relevant data.
We have two separate large-scale systems that data engineers need to manage.
Filesystems are cumbersome and much more difficult to both query and maintain.</p><p>It&rsquo;s worth noting that blob storage has several clear advantages:</p><ol><li>Cheaper to store data.</li><li>Contains storage tiers, such as archival, cold, and warm.</li><li>Can hold data of any type or size (audio, images, executables, etc.).<ul><li>Real unstructured data like audio can be used for ML piplines, text-to-speech algorithms, etc.</li></ul></li><li>Easy to replicate across regions and providers.</li></ol><h2 id=whats-a-data-lakehouse>What&rsquo;s a data lakehouse?<a hidden class=anchor aria-hidden=true href=#whats-a-data-lakehouse>#</a></h2><p>A data warehouse is storage for structured data. A data lake is storage for unstructured data. A <strong>data lakehouse</strong> is the beautiful storage love child of the warehouse and lake.
The lakehouse leverages the semi-structured JSON column of BigQuery and helps us ingest a flexible data structure while the native columns act as our metastore.</p><h2 id=lakehouse-example>Lakehouse example<a hidden class=anchor aria-hidden=true href=#lakehouse-example>#</a></h2><p>In this example, we use several columns for partioning (timestamp) and clustering (event_name, source). They act as metadata to our semi-structured data.
This way it&rsquo;s easy to navigate and explore data via SQL and to narrow down the subset of data we need. We can then use the new native JSON notation in our query:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>SELECT</span> id, <span style=color:#66d9ef>timestamp</span>, event_name, <span style=color:#66d9ef>data</span>.hello <span style=color:#66d9ef>FROM</span> datalake
</span></span></code></pre></div><p>Next, we use materialized-views or scheduled queries (via BigQuery/Airflow etc.) to build our final facts and dimensions tables.</p><table><thead><tr><th>id</th><th>timestamp</th><th>event_name</th><th>source</th><th>content_type</th><th>data</th><th>data_bytes</th></tr></thead><tbody><tr><td>6EF89A2E-8E11-4848-91B3-11682020559F</td><td>Sun Mar 6 15:48:24 IST 2022</td><td>something_happened</td><td>service-a</td><td>application/json</td><td><code>{"hello": "from lakehouse"}</code></td><td>NULL</td></tr></tbody></table><h2 id=easy-etls-with-materialized-views>Easy ETLs with <a href=https://cloud.google.com/bigquery/docs/materialized-views-intro>materialized-views</a><a hidden class=anchor aria-hidden=true href=#easy-etls-with-materialized-views>#</a></h2><p>IMHO SQL is a great language to use to describe data.
SQL is making a noticeable come back. Even Elastic and MongoDB support SQL. The rise of new-SQL databases like CockroachDB, modern warehouses, logging systems, etc. are clear evidence that SQL is here to stay.</p><p>We will use a cheap form of ETL using BigQuery&rsquo;s materialized-view feature.
The default refresh rate for materialized-view is 30m, you can of course tweak that, but it&rsquo;s sufficient for most workloads.</p><blockquote><p>If you already have such system in place you can use it as well.
See: Airflow, <code>dbt</code> or just a simple Kubernetes job.</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>CREATE</span> MATERIALIZED <span style=color:#66d9ef>VIEW</span> <span style=color:#f92672>`&lt;</span>project_id<span style=color:#f92672>&gt;</span>.<span style=color:#f92672>&lt;</span>dataset<span style=color:#f92672>&gt;</span>.canary_tests<span style=color:#f92672>`</span>
</span></span><span style=display:flex><span>PARTITION <span style=color:#66d9ef>BY</span> TIMESTAMP_TRUNC(<span style=color:#66d9ef>timestamp</span>, HOUR)
</span></span><span style=display:flex><span><span style=color:#66d9ef>CLUSTER</span> <span style=color:#66d9ef>BY</span> service_name <span style=color:#66d9ef>AS</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>SELECT</span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>timestamp</span>,
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>data</span>.service_name <span style=color:#66d9ef>AS</span> service_name,
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>data</span>.job_name <span style=color:#66d9ef>AS</span> job_name,
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>data</span>.workflow_id <span style=color:#66d9ef>AS</span> workflow_id,
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>data</span>.test_name <span style=color:#66d9ef>AS</span> test_name,
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>data</span>.build_url <span style=color:#66d9ef>as</span> build_url,
</span></span><span style=display:flex><span><span style=color:#66d9ef>FROM</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>`&lt;</span>project_id<span style=color:#f92672>&gt;</span>.<span style=color:#f92672>&lt;</span>dataset<span style=color:#f92672>&gt;</span>.datalake_v1<span style=color:#f92672>`</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>WHERE</span>
</span></span><span style=display:flex><span>  event_name <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;something_happened&#34;</span>
</span></span></code></pre></div><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>BigQuery is an excellent candidate to serve as the basis for your next data lake adventure (good luck!).</p><ul><li>BigQuery can help you start small and easily scale out.</li><li>Organizations of all sizes will benefit (if you don&rsquo;t store anything you won&rsquo;t pay for it).</li><li>Data engineering teams can build an impressive data platform levereging the power of SQL.</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://or-e.net/tags/bigquery/>Bigquery</a></li><li><a href=https://or-e.net/tags/data/>Data</a></li><li><a href=https://or-e.net/tags/google-cloud/>Google-Cloud</a></li></ul><nav class=paginav><a class=prev href=https://or-e.net/posts/grpc-details/><span class=title>« Prev</span><br><span>Add Protobuf messages into gRPC errors.</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://or-e.net/>Or Elimelech</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>